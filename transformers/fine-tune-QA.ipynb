{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_v2 = True\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model_checkpoint = \"/root/autodl-tmp/models/distilbert-base-uncased-finetuned-squad/20240327094912\"\n",
    "model_checkpoint = \"/root/autodl-tmp/models/distilbert-base-uncased-finetuned-squad/20240327102739\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request 61b7077b-4e66-4160-8a12-dcb0d1ef266d: GET https://hf-mirror.com/api/datasets/squad_v2 (authenticated: False)\n",
      "Request 61b7077b-4e66-4160-8a12-dcb0d1ef266d: GET https://hf-mirror.com/api/datasets/rajpurkar/squad_v2 (authenticated: False)\n",
      "Request cdd8fc10-0419-49a5-b99e-aab31de43cd0: GET https://hf-mirror.com/api/datasets/squad_v2 (authenticated: False)\n",
      "Request cdd8fc10-0419-49a5-b99e-aab31de43cd0: GET https://hf-mirror.com/api/datasets/rajpurkar/squad_v2 (authenticated: False)\n",
      "Request 7d9ca049-2a27-4494-8049-ab2365315383: GET https://hf-mirror.com/api/datasets/squad_v2/revision/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 7d9ca049-2a27-4494-8049-ab2365315383: GET https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/revision/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request c81ce3dd-263f-400b-9c01-3f6ca5682586: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request c81ce3dd-263f-400b-9c01-3f6ca5682586: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request fd8619c0-1cf6-4f98-bde6-1ed21f7f3be4: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request fd8619c0-1cf6-4f98-bde6-1ed21f7f3be4: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request df4b416a-3c5a-4a29-b1c5-50646cb29fe4: GET https://hf-mirror.com/api/datasets/squad_v2/tree/3ffb306f725f7d2ce8394bc1873b24868140c412/squad_v2?recursive=False&expand=False (authenticated: False)\n",
      "Request df4b416a-3c5a-4a29-b1c5-50646cb29fe4: GET https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/tree/3ffb306f725f7d2ce8394bc1873b24868140c412/squad_v2?recursive=False&expand=False (authenticated: False)\n",
      "Request 635ae491-604b-4b75-8305-1dabb963b7d1: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 635ae491-604b-4b75-8305-1dabb963b7d1: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request b51bdbf7-96f8-4f8d-b52d-2ff35e20a9d3: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request b51bdbf7-96f8-4f8d-b52d-2ff35e20a9d3: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 4ae2b9aa-73ea-404b-abea-dd965198d1ac: GET https://hf-mirror.com/api/datasets/squad_v2/revision/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 4ae2b9aa-73ea-404b-abea-dd965198d1ac: GET https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/revision/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request eaa14419-182d-4bc1-bc07-8e1d3f33a41f: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request eaa14419-182d-4bc1-bc07-8e1d3f33a41f: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 54543f5d-5bc0-4563-8d7f-86e152dfd28f: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 54543f5d-5bc0-4563-8d7f-86e152dfd28f: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 9bb0eeff-b38c-47be-b1e3-fca65599f188: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 9bb0eeff-b38c-47be-b1e3-fca65599f188: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request d7a875d7-a058-48de-8ab4-e012de968071: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request d7a875d7-a058-48de-8ab4-e012de968071: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 730a3f9d-afa3-4526-aa1a-321fd9202ada: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 730a3f9d-afa3-4526-aa1a-321fd9202ada: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request febe7e49-3171-4c36-aef3-5a6d57c3d949: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request febe7e49-3171-4c36-aef3-5a6d57c3d949: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 4fd553c3-0fd4-4542-a918-2754236d6e9a: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 4fd553c3-0fd4-4542-a918-2754236d6e9a: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request b901c642-4833-4f6e-8562-1b59da331dd4: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request b901c642-4833-4f6e-8562-1b59da331dd4: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 1b92ea94-a9e4-4e1f-9b68-9237ecb95ba1: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 1b92ea94-a9e4-4e1f-9b68-9237ecb95ba1: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request d942b811-4fae-4fd5-81b3-6fd321a06516: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request d942b811-4fae-4fd5-81b3-6fd321a06516: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 79d5df28-3030-4903-b0ee-fa1bc1943be4: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 79d5df28-3030-4903-b0ee-fa1bc1943be4: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 5a4a3c34-d0d7-4383-83fd-de605682d778: POST https://hf-mirror.com/api/datasets/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n",
      "Request 5a4a3c34-d0d7-4383-83fd-de605682d778: POST https://hf-mirror.com/api/datasets/rajpurkar/squad_v2/paths-info/3ffb306f725f7d2ce8394bc1873b24868140c412 (authenticated: False)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a86033cb4e223001a8e738b</td>\n",
       "      <td>War_on_Terror</td>\n",
       "      <td>In 2005, the UN Security Council adopted Resolution 1624 concerning incitement to commit acts of terrorism and the obligations of countries to comply with international human rights laws. Although both resolutions require mandatory annual reports on counter-terrorism activities by adopting nations, the United States and Israel have both declined to submit reports. In the same year, the United States Department of Defense and the Chairman of the Joint Chiefs of Staff issued a planning document, by the name \"National Military Strategic Plan for the War on Terrorism\", which stated that it constituted the \"comprehensive military plan to prosecute the Global War on Terror for the Armed Forces of the United States...including the findings and recommendations of the 9/11 Commission and a rigorous examination with the Department of Defense\".</td>\n",
       "      <td>What document did the Israeli Department of Defense publish?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a122c736614be00188f2489</td>\n",
       "      <td>Exhibition_game</td>\n",
       "      <td>An exhibition game (also known as a friendly, a scrimmage, a demonstration, a preseason game, a warmup match, or a preparation match, depending at least in part on the sport) is a sporting event whose prize money and impact on the player's or the team's rankings is either zero or otherwise greatly reduced. In team sports, matches of this type are often used to help coaches and managers select players for the competitive matches of a league season or tournament. If the players usually play in different teams in other leagues, exhibition games offer an opportunity for the players to learn to work with each other. The games can be held between separate teams or between parts of the same team.</td>\n",
       "      <td>Who does this type of game help players choose?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56d460ca2ccc5a1400d83103</td>\n",
       "      <td>Kanye_West</td>\n",
       "      <td>808s &amp; Heartbreak, which features extensive use of the eponymous Roland TR-808 drum machine and contains themes of love, loneliness, and heartache, was released by Island Def Jam to capitalize on Thanksgiving weekend in November 2008. Reviews were positive, though slightly more mixed than his previous efforts. Despite this, the record's singles demonstrated outstanding chart performances. Upon its release, the lead single \"Love Lockdown\" debuted at number three on the Billboard Hot 100 and became a \"Hot Shot Debut\", while follow-up single \"Heartless\" performed similarly and became his second consecutive \"Hot Shot Debut\" by debuting at number four on the Billboard Hot 100. While it was criticized prior to release, 808s &amp; Heartbreak had a significant effect on hip-hop music, encouraging other rappers to take more creative risks with their productions.</td>\n",
       "      <td>808s &amp; Heartbreak was released by what company?</td>\n",
       "      <td>{'text': ['Island Def Jam'], 'answer_start': [164]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56f8d67a9b226e1400dd10bc</td>\n",
       "      <td>Gene</td>\n",
       "      <td>Genes with a most recent common ancestor, and thus a shared evolutionary ancestry, are known as homologs. These genes appear either from gene duplication within an organism's genome, where they are known as paralogous genes, or are the result of divergence of the genes after a speciation event, where they are known as orthologous genes,:7.6 and often perform the same or similar functions in related organisms. It is often assumed that the functions of orthologous genes are more similar than those of paralogous genes, although the difference is minimal.</td>\n",
       "      <td>What are genes that result from divergence of the genes after a speciation event called?</td>\n",
       "      <td>{'text': ['orthologous genes'], 'answer_start': [320]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ad2de9dd7d075001a42a590</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>Some authors argue that anthropology originated and developed as the study of \"other cultures\", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal Exploring the City: Inquiries Toward an Urban Anthropology mentions that the \"Third World\" had habitually received most of attention; anthropologists who traditionally specialized in \"other cultures\" looked for them far away and started to look \"across the tracks\" only in late 1960s.</td>\n",
       "      <td>What do some authors argue developed as the study of western culture in terms of time and space?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5728fb8a6aef05140015493f</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>In the same war, the Prussian Edward Schnell served the Aizu domain as a military instructor and procurer of weapons. He was granted the Japanese name Hiramatsu Buhei (平松武兵衛), which inverted the characters of the daimyo's name Matsudaira. Hiramatsu (Schnell) was given the right to wear swords, as well as a residence in the castle town of Wakamatsu, a Japanese wife, and retainers. In many contemporary references, he is portrayed wearing a Japanese kimono, overcoat, and swords, with Western riding trousers and boots.</td>\n",
       "      <td>What was Edward Schnell's Japanese name?</td>\n",
       "      <td>{'text': ['Hiramatsu Buhei'], 'answer_start': [151]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5a3b5bd73ff257001ab84436</td>\n",
       "      <td>Rule_of_law</td>\n",
       "      <td>In 1959, an international gathering of over 185 judges, lawyers, and law professors from 53 countries, meeting in New Delhi and speaking as the International Commission of Jurists, made a declaration as to the fundamental principle of the rule of law. This was the Declaration of Delhi. They declared that the rule of law implies certain rights and freedoms, that it implies an independent judiciary, and that it implies social, economic and cultural conditions conducive to human dignity. The Declaration of Delhi did not, however, suggest that the rule of law requires legislative power to be subject to judicial review.</td>\n",
       "      <td>What commission has fifty-three members?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5a518f14b308da001a5a22fc</td>\n",
       "      <td>Southeast_Asia</td>\n",
       "      <td>The Andaman and Nicobar Islands of India are geographically considered part of Southeast Asia. Eastern Bangladesh and the Seven Sister States of India are culturally part of Southeast Asia and sometimes considered both South Asian and Southeast Asian. The Seven Sister States of India are also geographically part of Southeast Asia.[citation needed] The rest of the island of New Guinea which is not part of Indonesia, namely, Papua New Guinea, is sometimes included so are Palau, Guam, and the Northern Mariana Islands, which were all part of the Spanish East Indies.[citation needed]</td>\n",
       "      <td>What islands are not culturally or geographically part of Southeast Asia?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56cf3862aab44d1400b88e8f</td>\n",
       "      <td>New_York_City</td>\n",
       "      <td>Ecuador, Colombia, Guyana, Peru, and Brazil were the top source countries from South America for legal immigrants to the New York City region in 2013; the Dominican Republic, Jamaica, Haiti, and Trinidad and Tobago in the Caribbean; Egypt, Ghana, and Nigeria from Africa; and El Salvador, Honduras, and Guatemala in Central America. Amidst a resurgence of Puerto Rican migration to New York City, this population had increased to approximately 1.3 million in the metropolitan area as of 2013.</td>\n",
       "      <td>Out of all nations in Central America, which provided the most legal immigrants in 2013?</td>\n",
       "      <td>{'text': ['El Salvador'], 'answer_start': [276]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56e109accd28a01900c67498</td>\n",
       "      <td>BeiDou_Navigation_Satellite_System</td>\n",
       "      <td>In 2008, a BeiDou-1 ground terminal cost around CN¥20,000RMB (US$2,929), almost 10 times the price of a contemporary GPS terminal. The price of the terminals was explained as being due to the cost of imported microchips. At the China High-Tech Fair ELEXCON of November 2009 in Shenzhen, a BeiDou terminal priced at CN¥3,000RMB was presented.</td>\n",
       "      <td>How much more did a BeiDou-1 ground terminal cost than a current GPS terminal?</td>\n",
       "      <td>{'text': ['almost 10 times the price'], 'answer_start': [73]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length of a feature (question and context)\n",
    "max_length = 384 \n",
    "# The authorized overlap between two part of the context when splitting it is needed.\n",
    "doc_stride = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(datasets[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "# 挑选出来超过384（最大长度）的数据样例\n",
    "example = datasets[\"train\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"],\n",
    "              example[\"context\"],\n",
    "              max_length=max_length,\n",
    "              truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 192]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_example[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] beyonce got married in 2008 to whom? [SEP] on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five songs \" if i were a boy \" and \" halo \". achieving the accomplishment of becoming her longest - running hot 100 single in her career, \" halo \"'s success in the us helped beyonce attain more top - ten singles on the list than any other woman during the 2000s. it also included the successful \" sweet dreams \", and singles \" diva \", \" ego \", \" broken - hearted girl \" and \" video phone \". the music video for \" single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce [SEP]\n",
      "[CLS] beyonce got married in 2008 to whom? [SEP] single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce improvising a re - presentation of swift's award during her own acceptance speech. in march 2009, beyonce embarked on the i am... world tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $ 119. 5 million. [SEP]\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 7), (8, 11), (12, 19), (20, 22), (23, 27), (28, 30), (31, 35), (35, 36), (0, 0), (0, 2), (3, 8), (9, 10), (10, 11), (12, 16), (16, 17), (18, 25), (26, 33), (34, 37), (38, 39), (39, 40), (41, 44), (45, 53), (54, 62), (63, 68), (69, 77), (78, 80), (81, 82), (83, 88), (89, 93), (93, 96), (97, 99), (100, 103), (104, 113), (114, 119), (120, 123), (124, 127), (128, 133), (134, 140), (141, 146), (146, 147), (148, 149), (150, 152), (152, 153), (153, 154), (154, 155), (156, 161), (162, 168), (168, 169), (170, 172), (173, 182), (182, 183), (183, 184), (185, 189), (190, 194), (195, 197), (198, 205), (206, 208), (208, 209), (210, 214), (214, 215), (216, 217), (218, 220), (220, 221), (221, 222), (222, 223), (224, 229), (230, 236), (237, 240), (241, 249), (250, 252), (253, 261), (262, 264), (264, 265), (266, 270), (271, 273), (274, 277), (278, 284), (285, 291), (291, 292), (293, 296), (297, 302), (303, 311), (312, 322), (323, 330), (330, 331), (331, 332), (333, 338), (339, 342), (343, 348), (349, 355), (355, 356), (357, 366), (367, 373), (374, 377), (378, 384), (385, 387), (388, 391), (392, 396), (397, 403)]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonce Beyonce\n"
     ]
    }
   ],
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got got\n"
     ]
    }
   ],
   "source": [
    "second_token_id = tokenized_example[\"input_ids\"][0][2]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][2]\n",
    "print(tokenizer.convert_ids_to_tokens([second_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyonce got married in 2008 to whom?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 19\n"
     ]
    }
   ],
   "source": [
    "answers = example[\"answers\"]\n",
    "start_char = answers[\"answer_start\"][0]\n",
    "end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "# 当前span在文本中的起始标记索引。\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "# 当前span在文本中的结束标记索引。\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "# 检测答案是否超出span范围（如果超出范围，该特征将以CLS标记索引标记）。\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # 将token_start_index和token_end_index移动到答案的两端。\n",
    "    # 注意：如果答案是最后一个单词，我们可以移到最后一个标记之后（边界情况）。\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"答案不在此特征中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay z\n",
      "Jay Z\n"
     ]
    }
   ],
   "source": [
    "# 通过查找 offset mapping 位置，解码 context 中的答案 \n",
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "# 直接打印 数据集中的标准答案（answer[\"text\"])\n",
    "print(answers[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # 一些问题的左侧可能有很多空白字符，这对我们没有用，而且会导致上下文的截断失败\n",
    "    # （标记化的问题将占用大量空间）。因此，我们删除左侧的空白字符。\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和填充对我们的示例进行标记化，但保留溢出部分，使用步幅（stride）。\n",
    "    # 当上下文很长时，这会导致一个示例可能提供多个特征，其中每个特征的上下文都与前一个特征的上下文有一些重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例可能给我们提供多个特征（如果它具有很长的上下文），我们需要一个从特征到其对应示例的映射。这个键就提供了这个映射关系。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # 偏移映射将为我们提供从令牌到原始上下文中的字符位置的映射。这将帮助我们计算开始位置和结束位置。\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # 让我们为这些示例进行标记！\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # 我们将使用 CLS 特殊 token 的索引来标记不可能的答案。\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # 获取与该示例对应的序列（以了解上下文和问题是什么）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 一个示例可以提供多个跨度，这是包含此文本跨度的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # 如果没有给出答案，则将cls_index设置为答案。\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # 答案在文本中的开始和结束字符索引。\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # 当前跨度在文本中的开始令牌索引。\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # 当前跨度在文本中的结束令牌索引。\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 检测答案是否超出跨度（在这种情况下，该特征的标签将使用CLS索引）。\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # 否则，将token_start_index和token_end_index移到答案的两端。\n",
    "                # 注意：如果答案是最后一个单词（边缘情况），我们可以在最后一个偏移之后继续。\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 130319/130319 [00:27<00:00, 4734.08 examples/s]\n",
      "Map: 100%|██████████| 11873/11873 [00:02<00:00, 4800.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(prepare_train_features,\n",
    "                                  batched=True,\n",
    "                                  remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=96\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_dateTime = datetime.now()\n",
    "\n",
    "# 格式化为 yyyyMMddHHmmss\n",
    "formatted_dateTime = current_dateTime.strftime(\"%Y%m%d%H%M%S\")\n",
    "model_save_path=os.environ[\"MODEL_SAVE_PATH\"]\n",
    "if '/root/' in model_checkpoint:\n",
    "    model_checkpoint=\"distilbert-base-uncased\"\n",
    "model_dir = f\"{model_save_path}models/{model_checkpoint}-finetuned-squad/{formatted_dateTime}\"\n",
    "# distilbert-base-uncased\n",
    "args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3435' max='3435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3435/3435 30:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.042100</td>\n",
       "      <td>1.313069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>1.416938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>1.621011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.740300</td>\n",
       "      <td>1.491930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>1.634576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3435, training_loss=0.8298106008915574, metrics={'train_runtime': 1807.807, 'train_samples_per_second': 364.403, 'train_steps_per_second': 1.9, 'total_flos': 6.455275703106048e+16, 'train_loss': 0.8298106008915574, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存:/root/autodl-tmp/models/distilbert-base-uncased-finetuned-squad/20240327102739\n"
     ]
    }
   ],
   "source": [
    "model_to_save = trainer.save_model(model_dir)\n",
    "print(f\"模型已保存:{model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = trainer.model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([192, 384]), torch.Size([192, 384]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 49,  37,  72,  80, 157,  17,  44,  85, 148, 202, 119,  52,  22,  31,\n",
       "           0, 120,   0,  30,  90,   0,   0,  56,  88, 152,  23,   0,   0, 138,\n",
       "           0,   0, 128,   0,  72,  32,   0,   0,  93,   0,  93, 124,  40,  13,\n",
       "          33,  55,  98,  29,  80,   0,  28,  29,   0,   0, 139,  70,  49,   0,\n",
       "          47,   0,  74,  48,  16,   0,   0,  12,   0, 281,  41, 108,   0,  15,\n",
       "           0,   0,   0,   0,   0,   0,   0, 182,  28,  83,   0,  36,  34,  32,\n",
       "          69,  72,  38,  46,  57,  65,  67,  89,   0,  63,  92,  67,  39,  21,\n",
       "          91,  31,  69, 104,  25,  11,  10,  43,  11,   0,  42,  78,   0,   0,\n",
       "          82,  65,  36,  29,  60,   0,  13, 109,  39,  39,  65,  94,  41,   0,\n",
       "          97,  58,  82,  61,   0,  39,  55,  25,  22,  37,  19,   0,  29,  63,\n",
       "         102,  42,   0,  60,   0,  74,  39, 102,  75,  30,  45,   0,  16,  34,\n",
       "          53,  15,  13,   0,   0,   0,  47, 124, 113,   0, 111,   0,   0,   0,\n",
       "           0,  11,  49,  49,  20,  43,  33,  47,   0,   0,   0,  29,  69,  71,\n",
       "          24,  24,  68,   0,   0,  46,  35,  90,  18,  42], device='cuda:0'),\n",
       " tensor([ 49,  40,  76,  81, 157,  19,  44, 101, 153, 204, 120,  53,  26,  33,\n",
       "           0, 121,   0,  30,  91,   0,   0,  56,  94, 153,  24,   0,   0, 142,\n",
       "          16,   0, 149,   0,  72,  32,   0,   0,  94,  27,  94, 128,  44,  15,\n",
       "          50,  68, 104,  30,  81,   0,  29,  30,   0,  80,  66,  71,  51,   0,\n",
       "          49,   0,  82,  52,  17,   0,   0,  15,   0, 283,  43, 110,   0,  18,\n",
       "           0,   0,   0,   0,   0,   0,   0, 184,  30,  86,   0,  38,  34,  33,\n",
       "          59,  72,  39,  48,  61,  69,  71,  89,   0,  63,  93,  15,  42,  22,\n",
       "          95,  32,  70, 104,  27,  15,  11,  45,  12,   0,  44,  81,   0,   0,\n",
       "          88,   0,  37,  31, 129,   0,  15, 113,  39,  42,  66,  94,  41,   0,\n",
       "          99,  62,  82,  65,   0,  39,  56,  28,  24,  41,  20,   0,  30,  64,\n",
       "         106,  42,   0,  64,   0,  75,  41, 102,  76,  35,  46,   0,  23,  35,\n",
       "          56,  16,  17,   0,  14,   0,  51, 124, 117,   0, 115,   0,   0,   0,\n",
       "           0,  13,  52,  52,  20,   0,  34,  47,   0,   0,   0,  33,  70,  72,\n",
       "          26,  26,  71,   0,   0,  48,  37,  91,  19,  43], device='cuda:0'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "\n",
    "# 获取最佳的起始和结束位置的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "valid_answers = []\n",
    "\n",
    "# 遍历起始位置和结束位置的索引组合\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index:  # 需要进一步测试以检查答案是否在上下文中\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\"  # 我们需要找到一种方法来获取与上下文中答案对应的原始子字符串\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # 一些问题的左侧有很多空白，这些空白并不有用且会导致上下文截断失败（分词后的问题会占用很多空间）。\n",
    "    # 因此我们移除这些左侧空白\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和可能的填充对我们的示例进行分词，但使用步长保留溢出的令牌。这导致一个长上下文的示例可能产生\n",
    "    # 几个特征，每个特征的上下文都会稍微与前一个特征的上下文重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例在上下文很长时可能会产生几个特征，我们需要一个从特征映射到其对应示例的映射。这个键就是为了这个目的。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # 我们保留产生这个特征的示例ID，并且会存储偏移映射。\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # 获取与该示例对应的序列（以了解哪些是上下文，哪些是问题）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # 一个示例可以产生几个文本段，这里是包含该文本段的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # 将不属于上下文的偏移映射设置为None，以便容易确定一个令牌位置是否属于上下文。\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11873/11873 [00:03<00:00, 3322.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 12.627944, 'text': 'France'},\n",
       " {'score': 6.3091264, 'text': 'France.'},\n",
       " {'score': 4.6143856, 'text': 'a region in France'},\n",
       " {'score': 3.3296072, 'text': 'in France'},\n",
       " {'score': 3.1768882,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark'},\n",
       " {'score': 3.001429,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway'},\n",
       " {'score': 2.903132, 'text': 'region in France'},\n",
       " {'score': 1.8350077, 'text': 'Normandy, a region in France'},\n",
       " {'score': 0.71271133,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland'},\n",
       " {'score': 0.42838526,\n",
       "  'text': 'French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': 0.34033012, 'text': ', a region in France'},\n",
       " {'score': 0.19493198,\n",
       "  'text': '10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': 0.0757494,\n",
       "  'text': 'in the 10th and 11th centuries gave their name to Normandy, a region in France'},\n",
       " {'score': -0.040953636,\n",
       "  'text': 'France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates'},\n",
       " {'score': -1.704432, 'text': 'a region in France.'},\n",
       " {'score': -2.9892101, 'text': 'in France.'},\n",
       " {'score': -3.4156854, 'text': 'region in France.'},\n",
       " {'score': -4.48381, 'text': 'Normandy, a region in France.'},\n",
       " {'score': -4.8366704,\n",
       "  'text': 'a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark'},\n",
       " {'score': -5.01213,\n",
       "  'text': 'a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "\n",
    "# 第一个特征来自第一个示例。对于更一般的情况，我们需要将example_id匹配到一个示例索引\n",
    "context = datasets[\"validation\"][0][\"context\"]\n",
    "\n",
    "# 收集最佳开始/结束逻辑的索引：\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # 我们需要细化这个测试，以检查答案是否在上下文中\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['France', 'France', 'France', 'France'],\n",
       " 'answer_start': [159, 159, 159, 159]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"validation\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"validation\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # 构建一个从示例到其对应特征的映射。\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # 我们需要填充的字典。\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # 日志记录。\n",
    "    print(f\"正在后处理 {len(examples)} 个示例的预测，这些预测分散在 {len(features)} 个特征中。\")\n",
    "\n",
    "    # 遍历所有示例！\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # 这些是与当前示例关联的特征的索引。\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # 仅在squad_v2为True时使用。\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        # 遍历与当前示例关联的所有特征。\n",
    "        for feature_index in feature_indices:\n",
    "            # 我们获取模型对这个特征的预测。\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # 这将允许我们将logits中的某些位置映射到原始上下文中的文本跨度。\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # 更新最小空预测。\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # 浏览所有的最佳开始和结束logits，为 `n_best_size` 个最佳选择。\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # 在极少数情况下我们没有一个非空预测，我们创建一个假预测以避免失败。\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # 选择我们的最终答案：最佳答案或空答案（仅适用于squad_v2）\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在后处理 11873 个示例的预测，这些预测分散在 12134 个特征中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11873/11873 [00:21<00:00, 541.40it/s]\n"
     ]
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11669/1861587840.py:11: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
      "/root/miniconda3/envs/glm/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for squad_v2 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/squad_v2/squad_v2.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 61.37454729217552,\n",
       " 'f1': 65.14957015204033,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 65.5195681511471,\n",
       " 'HasAns_f1': 73.08043967867286,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 57.241379310344826,\n",
       " 'NoAns_f1': 57.241379310344826,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 61.38296976332856,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 65.15799262319355,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
